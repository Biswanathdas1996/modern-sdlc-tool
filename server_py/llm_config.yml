# =============================================================================
# LLM Configuration - Defuse 2.O
# =============================================================================

# Available Models:
#
#   Multimodal (text + image):
#   - vertex_ai.gemini-2.5-flash-image      — Fast & cheap. Handles text, images, code. Good for BRDs, docs, test cases, JIRA, BPMN, general tasks.
#   - vertex_ai.gemini-2.5-pro              — Deep reasoning over text & images. Best for complex analysis, security reviews, architecture decisions.
#
#   Text only:
#   - azure.gpt-5.2                         — Strong instruction follower. Great for detailed docs, structured output, nuanced writing, code review.
#   - vertex_ai.anthropic.claude-sonnet-4-6 — Top-tier coder. Excels at code generation, unit tests, bug fixes, refactoring, technical analysis.
#   - azure.grok-4-fast-reasoning           — Ultra-fast reasoning. Ideal for intent classification, search queries, short extractions, chat responses.
#
#   Audio:
#   - openai.whisper                        — Speech-to-text. Transcribes voice input into text for requirements capture.
#
#   Embeddings:
#   - vertex_ai.text-embedding-005          — 768-dim vectors. Powers knowledge base search and semantic similarity matching.
#   - vertex_ai.gemini-embedding            — Text embeddings for semantic search, document retrieval, and clustering.
# =============================================================================

defaults:
  model: vertex_ai.gemini-2.5-flash-image
  temperature: 0.2
  max_tokens: 6096
  timeout: 180

# ---------------------------------------------------------------------------
# Repository Analysis & Documentation
# ---------------------------------------------------------------------------
repo_analysis:
  model: vertex_ai.gemini-2.5-flash-image        # fast multimodal — good for scanning repo structure
  temperature: 0.2
  max_tokens: 6096

documentation_generation:
  model: azure.gpt-5.2                            # strong writing — detailed, well-structured docs
  temperature: 0.3
  max_tokens: 6096

# ---------------------------------------------------------------------------
# BRD & Business Artifacts
# ---------------------------------------------------------------------------
brd_generation:
  model: vertex_ai.gemini-2.5-pro                 # deep reasoning — complex business requirements need accuracy
  temperature: 0.3
  max_tokens: 8000

bpmn_diagram:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — structured diagram output
  temperature: 0.2
  max_tokens: 6096

user_story_generation:
  model: azure.gpt-5.2                            # strong writing — well-structured user stories
  temperature: 0.3
  max_tokens: 8192

copilot_prompt:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — generates precise dev prompts
  temperature: 0.2
  max_tokens: 8192

related_stories:
  model: azure.grok-4-fast-reasoning              # ultra-fast — quick semantic matching
  temperature: 0.2
  max_tokens: 4096

# ---------------------------------------------------------------------------
# Test Generation
# ---------------------------------------------------------------------------
test_case_generation:
  model: vertex_ai.gemini-2.5-pro                 # deep reasoning — thorough test coverage needs accuracy
  temperature: 0.2
  max_tokens: 8192

test_data_generation:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — bulk data generation
  temperature: 0.3
  max_tokens: 6096

# ---------------------------------------------------------------------------
# JIRA Agent
# ---------------------------------------------------------------------------
jira_agent:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — general JIRA orchestration
  temperature: 0.2
  max_tokens: 6096

jira_intent_extraction:
  model: azure.grok-4-fast-reasoning              # ultra-fast — quick classification task
  temperature: 0.1
  max_tokens: 500

jira_ticket_extraction:
  model: azure.grok-4-fast-reasoning              # ultra-fast — short structured extraction
  temperature: 0.1
  max_tokens: 500

jira_search:
  model: azure.grok-4-fast-reasoning              # ultra-fast — search query formulation
  temperature: 0.1
  max_tokens: 500

jira_knowledge_base:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — KB context retrieval
  temperature: 0.2
  max_tokens: 4096

jira_context_enrichment:
  model: azure.grok-4-fast-reasoning              # ultra-fast — quick context augmentation
  temperature: 0.1
  max_tokens: 500

jira_description_enhance:
  model: azure.gpt-5.2                            # strong writing — polished ticket descriptions
  temperature: 0.3
  max_tokens: 1500

jira_response_format:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — structured response formatting
  temperature: 0.3
  max_tokens: 2000

# ---------------------------------------------------------------------------
# Unit Test Agent
# ---------------------------------------------------------------------------
unit_test_analysis:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — understands code patterns
  temperature: 0.1
  max_tokens: 1000

unit_test_coverage:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — accurate coverage mapping
  temperature: 0.1
  max_tokens: 2000

unit_test_discovery:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — scanning existing tests
  temperature: 0.1
  max_tokens: 2000

unit_test_generation:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — writes quality test code
  temperature: 0.1
  max_tokens: 8192

unit_test_fix:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — precise bug fixing
  temperature: 0.15
  max_tokens: 8192

# ---------------------------------------------------------------------------
# Code Generation Agent
# ---------------------------------------------------------------------------
code_gen_plan:
  model: vertex_ai.gemini-2.5-pro                 # deep reasoning — architectural planning
  temperature: 0.3
  max_tokens: 6096

code_gen_implementation:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — writes production-quality code
  temperature: 0.2
  max_tokens: 6096

# ---------------------------------------------------------------------------
# Security Agent (Shannon)
# ---------------------------------------------------------------------------
security_analysis:
  model: vertex_ai.gemini-2.5-pro                 # deep reasoning — thorough vulnerability detection
  temperature: 0.2
  max_tokens: 6096

security_assessment:
  model: vertex_ai.gemini-2.5-pro                 # deep reasoning — comprehensive risk assessment
  temperature: 0.5
  max_tokens: 6096

# ---------------------------------------------------------------------------
# Web Test Agent
# ---------------------------------------------------------------------------
web_test_generation:
  model: vertex_ai.anthropic.claude-sonnet-4-6    # top-tier coder — writes reliable test scripts
  temperature: 0.3
  max_tokens: 8192

web_test_analysis:
  model: vertex_ai.gemini-2.5-flash-image         # fast multimodal — can analyze screenshots + logs
  temperature: 0.4
  max_tokens: 8192
